{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória de Dados (EDA) - Olist E-Commerce Dataset\n",
    "\n",
    "Este notebook consolida, limpa e analisa um conjunto de dados de e-commerce da Olist. O objetivo é extrair insights sobre vendas, desempenho de entrega e satisfação do cliente.\n",
    "\n",
    "**Estrutura do Projeto:**\n",
    "1.  **Setup do Ambiente**: Importação de bibliotecas e configurações.\n",
    "2.  **Carregamento e Consolidação**: Funções para carregar e unir os múltiplos arquivos CSV.\n",
    "3.  **Limpeza e Pré-processamento**: Função para tratar valores ausentes, converter tipos de dados e remover duplicatas.\n",
    "4.  **Engenharia de Atributos**: Criação de novas colunas (features) para uma análise mais profunda.\n",
    "5.  **Análise Exploratória e Visualização**: Funções para gerar gráficos e estatísticas descritivas.\n",
    "6.  **Execução Principal**: Chamada sequencial de todas as etapas da análise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup do Ambiente\n",
    "\n",
    "Nesta etapa, importamos todas as bibliotecas necessárias para a análise e configuramos os padrões visuais para os gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Configurações de visualização e avisos\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Carregamento e Consolidação dos Dados\n",
    "\n",
    "As funções abaixo são responsáveis por encontrar os arquivos `.csv` em um diretório e uni-los em um único DataFrame, criando uma visão consolidada do negócio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_folder: str) -> dict:\n",
    "    \"\"\"\n",
    "    Carrega todos os arquivos CSV do dataset Olist de um diretório especificado.\n",
    "\n",
    "    Args:\n",
    "        data_folder (str): O caminho para a pasta que contém os arquivos .csv.\n",
    "\n",
    "    Returns:\n",
    "        dict: Um dicionário onde as chaves são os nomes dos datasets e os\n",
    "              valores são os DataFrames do pandas correspondentes.\n",
    "    \"\"\"\n",
    "    datasets = {\n",
    "        \"customers\": \"olist_customers_dataset.csv\",\n",
    "        \"order_items\": \"olist_order_items_dataset.csv\",\n",
    "        \"payments\": \"olist_order_payments_dataset.csv\",\n",
    "        \"reviews\": \"olist_order_reviews_dataset.csv\",\n",
    "        \"orders\": \"olist_orders_dataset.csv\",\n",
    "        \"products\": \"olist_products_dataset.csv\",\n",
    "        \"sellers\": \"olist_sellers_dataset.csv\",\n",
    "        \"product_category\": \"product_category_name_translation.csv\",\n",
    "    }\n",
    "\n",
    "    dataframes = {}\n",
    "    print(\"Iniciando carregamento dos dados...\")\n",
    "    for name, filename in datasets.items():\n",
    "        file_path = os.path.join(data_folder, filename)\n",
    "        try:\n",
    "            dataframes[name] = pd.read_csv(file_path)\n",
    "            print(f\"  - Arquivo '{filename}' carregado com sucesso.\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"  - [ERRO] Arquivo não encontrado: {file_path}\")\n",
    "            return None\n",
    "    return dataframes\n",
    "\n",
    "def merge_data(dataframes: dict) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Realiza o merge sequencial dos dataframes da Olist em um único dataframe consolidado.\n",
    "\n",
    "    Args:\n",
    "        dataframes (dict): Dicionário de dataframes carregados pela função load_data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Um único dataframe contendo todos os dados unidos.\n",
    "    \"\"\"\n",
    "    if not dataframes:\n",
    "        return None\n",
    "\n",
    "    print(\"\\nIniciando merge dos dataframes...\")\n",
    "    # O dataframe de 'orders' é a tabela central\n",
    "    df = pd.merge(dataframes['orders'], dataframes['customers'], on='customer_id', how='left')\n",
    "    df = pd.merge(df, dataframes['order_items'], on='order_id', how='left')\n",
    "    df = pd.merge(df, dataframes['payments'], on='order_id', how='left')\n",
    "    df = pd.merge(df, dataframes['reviews'], on='order_id', how='left')\n",
    "    df = pd.merge(df, dataframes['products'], on='product_id', how='left')\n",
    "    df = pd.merge(df, dataframes['sellers'], on='seller_id', how='left')\n",
    "    df = pd.merge(df, dataframes['product_category'], on='product_category_name', how='left')\n",
    "\n",
    "    print(f\"Merge concluído. DataFrame consolidado com {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Limpeza e Pré-processamento\n",
    "\n",
    "Dados brutos raramente estão prontos para análise. Esta função executa as etapas essenciais de limpeza:\n",
    "- Converte colunas de texto para o formato de data/hora (`datetime`).\n",
    "- Aplica estratégias para tratar valores ausentes (`NaN`).\n",
    "- Remove quaisquer linhas duplicadas que possam existir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_preprocess_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Executa a limpeza completa do dataframe: conversão de tipos, tratamento de nulos e duplicatas.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): O dataframe consolidado.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: O dataframe limpo e pré-processado.\n",
    "    \"\"\"\n",
    "    print(\"\\nIniciando limpeza e pré-processamento...\")\n",
    "\n",
    "    # --- 1. Conversão de Tipos de Dados (Datas) ---\n",
    "    date_cols = [\n",
    "        'order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date',\n",
    "        'order_delivered_customer_date', 'order_estimated_delivery_date',\n",
    "        'review_creation_date', 'review_answer_timestamp', 'shipping_limit_date'\n",
    "    ]\n",
    "    for col in date_cols:\n",
    "        df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    print(f\"  - {len(date_cols)} colunas de data convertidas para datetime.\")\n",
    "\n",
    "    # --- 2. Tratamento de Valores Ausentes ---\n",
    "    numeric_product_cols = ['product_name_lenght', 'product_description_lenght', 'product_photos_qty']\n",
    "    for col in numeric_product_cols:\n",
    "        median_val = df[col].median()\n",
    "        df[col].fillna(median_val, inplace=True)\n",
    "\n",
    "    df['product_category_name'].fillna('unknown', inplace=True)\n",
    "    df['product_category_name_english'].fillna('unknown', inplace=True)\n",
    "\n",
    "    df.dropna(subset=['order_approved_at', 'order_delivered_customer_date'], inplace=True)\n",
    "    print(\"  - Valores ausentes tratados.\")\n",
    "\n",
    "    # --- 3. Remoção de Duplicatas ---\n",
    "    initial_rows = df.shape[0]\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    rows_removed = initial_rows - df.shape[0]\n",
    "    if rows_removed > 0:\n",
    "        print(f\"  - {rows_removed} linhas duplicadas foram removidas.\")\n",
    "    else:\n",
    "        print(\"  - Nenhuma linha duplicada encontrada.\")\n",
    "\n",
    "    print(f\"Limpeza concluída. DataFrame final com {df.shape[0]} linhas.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Engenharia de Atributos\n",
    "\n",
    "Esta é uma das etapas mais importantes da análise. Criamos novas colunas (atributos) a partir dos dados existentes para permitir insights mais profundos. Aqui, focamos em métricas de tempo de entrega e extraímos componentes das datas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Cria novos atributos úteis a partir dos dados existentes.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): O dataframe limpo.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: O dataframe com os novos atributos.\n",
    "    \"\"\"\n",
    "    print(\"\\nIniciando engenharia de atributos...\")\n",
    "\n",
    "    # --- Atributos Temporais ---\n",
    "    # Tempo de entrega (em dias)\n",
    "    df['delivery_time_days'] = (df['order_delivered_customer_date'] - df['order_approved_at']).dt.days\n",
    "\n",
    "    # Diferença entre entrega estimada e real (em dias)\n",
    "    df['delivery_delta_days'] = (df['order_estimated_delivery_date'] - df['order_delivered_customer_date']).dt.days\n",
    "\n",
    "    # Indicador de atraso na entrega\n",
    "    df['is_late'] = (df['delivery_delta_days'] < 0).astype(int)\n",
    "\n",
    "    # Extração de componentes da data da compra\n",
    "    df['purchase_year'] = df['order_purchase_timestamp'].dt.year\n",
    "    df['purchase_month'] = df['order_purchase_timestamp'].dt.month\n",
    "    df['purchase_day_of_week'] = df['order_purchase_timestamp'].dt.day_name()\n",
    "\n",
    "    print(\"  - Novos atributos criados: 'delivery_time_days', 'delivery_delta_days', 'is_late', e componentes de data.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análise Exploratória e Visualização (EDA)\n",
    "\n",
    "Com os dados limpos e enriquecidos, esta função gera as principais visualizações para responder a perguntas de negócio, como:\n",
    "- Qual é a tendência de vendas ao longo do tempo?\n",
    "- Quais são as categorias de produtos mais populares?\n",
    "- Os clientes estão satisfeitos? \n",
    "- O tempo de entrega influencia a satisfação do cliente?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_exploratory_data_analysis(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Realiza e exibe a análise exploratória dos dados através de estatísticas e gráficos.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): O dataframe com todos os atributos.\n",
    "    \"\"\"\n",
    "    print(\"\\n--- INICIANDO ANÁLISE EXPLORATÓRIA (EDA) ---\")\n",
    "\n",
    "    # --- Análise 1: Tendência de Vendas ao Longo do Tempo ---\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    sales_by_month = df.set_index('order_purchase_timestamp')['payment_value'].resample('M').sum()\n",
    "    sales_by_month.plot(kind='line', marker='o')\n",
    "    plt.title('Tendência Mensal de Vendas (Valor Total)', fontsize=16)\n",
    "    plt.xlabel('Mês da Compra')\n",
    "    plt.ylabel('Valor Total de Pagamento (R$)')\n",
    "    plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    # --- Análise 2: Top 10 Categorias de Produtos Mais Vendidas ---\n",
    "    plt.figure(figsize=(14, 7))\n",
    "    top_categories = df['product_category_name_english'].value_counts().nlargest(10)\n",
    "    sns.barplot(x=top_categories.values, y=top_categories.index, palette='viridis')\n",
    "    plt.title('Top 10 Categorias de Produtos Mais Vendidas', fontsize=16)\n",
    "    plt.xlabel('Número de Pedidos')\n",
    "    plt.ylabel('Categoria do Produto (Inglês)')\n",
    "    plt.show()\n",
    "\n",
    "    # --- Análise 3: Distribuição das Notas de Avaliação (Review Scores) ---\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.countplot(x='review_score', data=df, palette='rocket')\n",
    "    plt.title('Distribuição das Notas de Avaliação (Review Scores)', fontsize=16)\n",
    "    plt.xlabel('Nota da Avaliação')\n",
    "    plt.ylabel('Contagem de Pedidos')\n",
    "    plt.show()\n",
    "\n",
    "    # --- Análise 4: Relação entre Tempo de Entrega e Nota de Avaliação ---\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    sns.boxplot(x='review_score', y='delivery_time_days', data=df, palette='coolwarm')\n",
    "    plt.title('Tempo de Entrega (dias) por Nota de Avaliação', fontsize=16)\n",
    "    plt.xlabel('Nota da Avaliação')\n",
    "    plt.ylabel('Tempo de Entrega (dias)')\n",
    "    plt.ylim(0, df['delivery_time_days'].quantile(0.95)) # Remove outliers extremos para melhor visualização\n",
    "    plt.show()\n",
    "\n",
    "    # --- Análise 5: Matriz de Correlação de Variáveis Numéricas ---\n",
    "    cols_to_correlate = [\n",
    "        'price', 'freight_value', 'payment_value', 'review_score',\n",
    "        'delivery_time_days', 'delivery_delta_days', 'is_late'\n",
    "    ]\n",
    "    corr_matrix = df[cols_to_correlate].corr()\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=.5)\n",
    "    plt.title('Matriz de Correlação entre Variáveis Chave', fontsize=16)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Execução Principal\n",
    "\n",
    "Esta é a célula final que orquestra todo o fluxo. Ela define o caminho para os dados e chama cada uma das funções definidas anteriormente na ordem correta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATENÇÃO: Substitua pelo caminho correto da sua pasta de dados.\n",
    "# Se estiver usando o Google Colab, você precisará montar seu Drive primeiro.\n",
    "data_folder = '/content/drive/MyDrive/ANALISTA DE DADOS/portifolio/data'\n",
    "\n",
    "# Etapa 1: Carregar os dados\n",
    "dataframes = load_data(data_folder)\n",
    "\n",
    "if dataframes:\n",
    "    # Etapa 2: Unificar os dataframes\n",
    "    df_merged = merge_data(dataframes)\n",
    "\n",
    "    # Etapa 3: Limpeza e Pré-processamento\n",
    "    df_clean = clean_and_preprocess_data(df_merged)\n",
    "\n",
    "    # Etapa 4: Engenharia de Atributos\n",
    "    df_final = feature_engineering(df_clean)\n",
    "\n",
    "    # Exibe as 5 primeiras linhas do dataframe final para verificação\n",
    "    print(\"\\n--- Amostra do DataFrame Final ---\")\n",
    "    display(df_final.head())\n",
    "    \n",
    "    # Etapa 5: Análise Exploratória\n",
    "    perform_exploratory_data_analysis(df_final)\n",
    "\n",
    "    print(\"\\nAnálise concluída com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}